{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-03T01:02:12.925837500Z",
     "start_time": "2025-04-03T01:02:12.915991800Z"
    }
   },
   "id": "initial_id",
   "execution_count": 138
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This Python code focuses on cleaning HVAC - related merged data. It first reads in the \n",
    "merged data and converts the 'TIMESTAMP' column to datetime. Then, it performs a series of \n",
    "cleaning steps including preprocessing special values, handling missing values (using \n",
    "interpolation for numeric columns and filling with a specific string for text columns), and \n",
    "detecting outliers with Z - score method. Finally, it saves the cleaned data.**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b5b2742a1a56fa9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12503\\AppData\\Local\\Temp\\ipykernel_65824\\759342792.py:2: DtypeWarning: Columns (25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,65,66,67,68,69,70,71,72,73,74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  final_data = pd.read_csv('../../outputs/HVAC_merged_data.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load previously merged data\n",
    "final_data = pd.read_csv('../../outputs/HVAC_merged_data.csv')\n",
    "final_data['TIMESTAMP'] = pd.to_datetime(final_data['TIMESTAMP'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-03T01:02:14.069721700Z",
     "start_time": "2025-04-03T01:02:12.923831100Z"
    }
   },
   "id": "e9bbec203ee1593",
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def general_data_cleaning(df):\n",
    "    df, text_columns = preprocess_special_values(df)\n",
    "    # Missing value processing\n",
    "    df = handle_missing_values(df)\n",
    "\n",
    "    # outlier detection\n",
    "    df = detect_outliers(df, text_columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_special_values(df):\n",
    "    print(\"\\n=== Special Character Preprocessing ===\")\n",
    "    special_values = ['-', '--', '---', 'NA', 'N/A', 'NULL', 'NaN', '']\n",
    "    text_columns = ['source_file_y', 'source_file_x']  \n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in text_columns or col == 'TIMESTAMP':  \n",
    "            continue\n",
    "            \n",
    "        if df[col].dtype == 'object':\n",
    "            print(f\"Trying to convert column {col} to a numeric type...\")\n",
    "            try:\n",
    "                df[col] = df[col].replace(special_values, np.nan)\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')  \n",
    "                print(f\"  Successfully converted column {col} to a numeric type\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Conversion failed, remain as text column: {str(e)}\")\n",
    "                text_columns.append(col)\n",
    "        else:\n",
    "            text_columns.append(col)\n",
    "\n",
    "    # Processing text columns\n",
    "    for col in text_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"Processing text columns {col}\")\n",
    "            df[col] = df[col].replace(special_values, 'UNKNOWN')\n",
    "            df[col] = df[col].astype(str)  # Make sure it's a string type\n",
    "\n",
    "    return df, text_columns\n",
    "\n",
    "def detect_outliers(df, text_columns):\n",
    "    print(\"\\n=== outlier detection ===\")\n",
    "    # Detecting outliers in numeric columns using the Z-score method (excluding text and time columns)\n",
    "    numeric_cols = [col for col in df.select_dtypes(include=['float64', 'int64']).columns \n",
    "                   if col not in text_columns and col != 'TIMESTAMP']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # Ensure that there are no infinitely large or small values in the columns\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # Calculate Z-score\n",
    "        try:\n",
    "            valid_values = df[col].dropna()\n",
    "            if len(valid_values) < 2:  # 2 less values are needed to calculate the Z-score\n",
    "                print(f\"Column {col} Insufficient valid values, skip outlier detection\")\n",
    "                continue\n",
    "                \n",
    "            z_scores = np.abs(stats.zscore(valid_values))\n",
    "            \n",
    "            # Defining outlier thresholds\n",
    "            threshold = 3\n",
    "            outliers_mask = np.abs(stats.zscore(df[col].fillna(df[col].median()))) > threshold\n",
    "            outliers = df[col][outliers_mask]\n",
    "            \n",
    "            if not outliers.empty:\n",
    "                print(f\"Column {col} found {len(outliers)} outlier (Z-score > {threshold})\")\n",
    "                # Replace with median\n",
    "                median_val = df[col].median()\n",
    "                df.loc[outliers_mask, col] = median_val\n",
    "        except Exception as e:\n",
    "            print(f\"Unable to compute an outlier for column {col}.: {str(e)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    print(\"\\n=== Missing value handling ===\")\n",
    "    # Recognize text columns\n",
    "    text_columns = [col for col in df.columns \n",
    "                   if col.startswith('source_file_') or \n",
    "                      (df[col].dtype == 'object' and not pd.api.types.is_numeric_dtype(df[col]))]\n",
    "    \n",
    "    # Calculate the proportion of missing values in each column (excluding text columns)\n",
    "    missing_stats = df.drop(columns=text_columns, errors='ignore').isnull().mean().sort_values(ascending=False)\n",
    "    print(\"Statistics on the percentage of missing values in numeric columns:\")\n",
    "    print(missing_stats[missing_stats > 0])\n",
    "    \n",
    "    # Use linear interpolation for a small number of missing values in a numeric column\n",
    "    threshold = 0.1  # 10% as a threshold\n",
    "    for col in df.columns:\n",
    "        if col in text_columns or col == 'TIMESTAMP':\n",
    "            continue\n",
    "            \n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            if df[col].isnull().mean() < threshold:\n",
    "                df[col] = df[col].interpolate(method='linear')\n",
    "                print(f\"The numeric column {col} uses linear interpolation to fill in missing values.\")\n",
    "            elif df[col].isnull().mean() >= threshold:\n",
    "                print(f\"Numeric columns {col} High percentage of missing values ({df[col].isnull().mean():.2%})\")\n",
    "    \n",
    "    # Handling missing values in text columns\n",
    "    for col in text_columns:\n",
    "        if col in df.columns and df[col].isnull().any():\n",
    "            missing_count = df[col].isnull().sum()\n",
    "            df[col] = df[col].fillna('MISSING')\n",
    "            print(f\"The text column {col} is populated with {missing_count} with a missing value of 'MISSING'\")\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-03T01:02:14.143706400Z",
     "start_time": "2025-04-03T01:02:14.124595500Z"
    }
   },
   "id": "8f266efd0a009f36",
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin the data cleansing process...\n",
      "\n",
      "=== Special Character Preprocessing ===\n",
      "Trying to convert column T_Sup_RTU to a numeric type...\n",
      "  Successfully converted column T_Sup_RTU to a numeric type\n",
      "Trying to convert column RH_Sup_RTU to a numeric type...\n",
      "  Successfully converted column RH_Sup_RTU to a numeric type\n",
      "Trying to convert column T_Ret_RTU to a numeric type...\n",
      "  Successfully converted column T_Ret_RTU to a numeric type\n",
      "Trying to convert column RH_Ret_RTU to a numeric type...\n",
      "  Successfully converted column RH_Ret_RTU to a numeric type\n",
      "Trying to convert column T_VAV_102 to a numeric type...\n",
      "  Successfully converted column T_VAV_102 to a numeric type\n",
      "Trying to convert column T_VAV_103 to a numeric type...\n",
      "  Successfully converted column T_VAV_103 to a numeric type\n",
      "Trying to convert column T_VAV_104 to a numeric type...\n",
      "  Successfully converted column T_VAV_104 to a numeric type\n",
      "Trying to convert column T_VAV_105 to a numeric type...\n",
      "  Successfully converted column T_VAV_105 to a numeric type\n",
      "Trying to convert column T_VAV_106 to a numeric type...\n",
      "  Successfully converted column T_VAV_106 to a numeric type\n",
      "Trying to convert column T_VAV_202 to a numeric type...\n",
      "  Successfully converted column T_VAV_202 to a numeric type\n",
      "Trying to convert column T_VAV_203 to a numeric type...\n",
      "  Successfully converted column T_VAV_203 to a numeric type\n",
      "Trying to convert column T_VAV_204 to a numeric type...\n",
      "  Successfully converted column T_VAV_204 to a numeric type\n",
      "Trying to convert column T_VAV_205 to a numeric type...\n",
      "  Successfully converted column T_VAV_205 to a numeric type\n",
      "Trying to convert column T_VAV_206 to a numeric type...\n",
      "  Successfully converted column T_VAV_206 to a numeric type\n",
      "Trying to convert column RH_VAV_102 to a numeric type...\n",
      "  Successfully converted column RH_VAV_102 to a numeric type\n",
      "Trying to convert column RH_VAV_103 to a numeric type...\n",
      "  Successfully converted column RH_VAV_103 to a numeric type\n",
      "Trying to convert column RH_VAV_104 to a numeric type...\n",
      "  Successfully converted column RH_VAV_104 to a numeric type\n",
      "Trying to convert column RH_VAV_105 to a numeric type...\n",
      "  Successfully converted column RH_VAV_105 to a numeric type\n",
      "Trying to convert column RH_VAV_106 to a numeric type...\n",
      "  Successfully converted column RH_VAV_106 to a numeric type\n",
      "Trying to convert column RH_VAV_202 to a numeric type...\n",
      "  Successfully converted column RH_VAV_202 to a numeric type\n",
      "Trying to convert column RH_VAV_203 to a numeric type...\n",
      "  Successfully converted column RH_VAV_203 to a numeric type\n",
      "Trying to convert column RH_VAV_204 to a numeric type...\n",
      "  Successfully converted column RH_VAV_204 to a numeric type\n",
      "Trying to convert column RH_VAV_205 to a numeric type...\n",
      "  Successfully converted column RH_VAV_205 to a numeric type\n",
      "Trying to convert column RH_VAV_206 to a numeric type...\n",
      "  Successfully converted column RH_VAV_206 to a numeric type\n",
      "Trying to convert column AF_RTU to a numeric type...\n",
      "  Successfully converted column AF_RTU to a numeric type\n",
      "Trying to convert column AF_VAV_102 to a numeric type...\n",
      "  Successfully converted column AF_VAV_102 to a numeric type\n",
      "Trying to convert column AF_VAV_103 to a numeric type...\n",
      "  Successfully converted column AF_VAV_103 to a numeric type\n",
      "Trying to convert column AF_VAV_104 to a numeric type...\n",
      "  Successfully converted column AF_VAV_104 to a numeric type\n",
      "Trying to convert column AF_VAV_105 to a numeric type...\n",
      "  Successfully converted column AF_VAV_105 to a numeric type\n",
      "Trying to convert column AF_VAV_106 to a numeric type...\n",
      "  Successfully converted column AF_VAV_106 to a numeric type\n",
      "Trying to convert column AF_VAV_202 to a numeric type...\n",
      "  Successfully converted column AF_VAV_202 to a numeric type\n",
      "Trying to convert column AF_VAV_203 to a numeric type...\n",
      "  Successfully converted column AF_VAV_203 to a numeric type\n",
      "Trying to convert column AF_VAV_204 to a numeric type...\n",
      "  Successfully converted column AF_VAV_204 to a numeric type\n",
      "Trying to convert column AF_VAV_205 to a numeric type...\n",
      "  Successfully converted column AF_VAV_205 to a numeric type\n",
      "Trying to convert column AF_VAV_206 to a numeric type...\n",
      "  Successfully converted column AF_VAV_206 to a numeric type\n",
      "Processing text columns source_file_y\n",
      "Processing text columns source_file_x\n",
      "Processing text columns T_Stair_101\n",
      "Processing text columns T_Room_102\n",
      "Processing text columns T_Room_103\n",
      "Processing text columns T_Room_104\n",
      "Processing text columns T_Room_105\n",
      "Processing text columns T_Room_106\n",
      "Processing text columns T_Stair_201\n",
      "Processing text columns T_Room_202\n",
      "Processing text columns T_Room_203\n",
      "Processing text columns T_Room_204\n",
      "Processing text columns T_Room_205\n",
      "Processing text columns T_Room_206\n",
      "Processing text columns RH_Stair_101\n",
      "Processing text columns RH_Room_102\n",
      "Processing text columns RH_Room_103\n",
      "Processing text columns RH_Room_104\n",
      "Processing text columns RH_Room_105\n",
      "Processing text columns RH_Room_106\n",
      "Processing text columns RH_Stair_201\n",
      "Processing text columns RH_Room_202\n",
      "Processing text columns RH_Room_203\n",
      "Processing text columns RH_Room_204\n",
      "Processing text columns RH_Room_205\n",
      "Processing text columns RH_Room_206\n",
      "Processing text columns WH_RTU_Total\n",
      "Processing text columns WH_RTU_Comp1\n",
      "Processing text columns WH_RTU_Comp2\n",
      "Processing text columns WH_RTU_Cond1\n",
      "Processing text columns WH_RTU_Cond2\n",
      "Processing text columns WH_RTU_Sup_Fan\n",
      "Processing text columns WH_RTU_VAV102\n",
      "Processing text columns WH_RTU_VAV103\n",
      "Processing text columns WH_RTU_VAV104\n",
      "Processing text columns WH_RTU_VAV105\n",
      "Processing text columns WH_RTU_VAV106\n",
      "Processing text columns WH_RTU_VAV202\n",
      "Processing text columns WH_RTU_VAV203\n",
      "Processing text columns WH_RTU_VAV204\n",
      "Processing text columns WH_RTU_VAV205\n",
      "Processing text columns WH_RTU_VAV206\n",
      "Processing text columns T_out\n",
      "Processing text columns RH_out\n",
      "Processing text columns BP\n",
      "Processing text columns Dir_Solar\n",
      "Processing text columns Dif_Solar\n",
      "Processing text columns Glo_Solar\n",
      "Processing text columns WS\n",
      "Processing text columns WD\n",
      "\n",
      "=== Missing value handling ===\n",
      "Statistics on the percentage of missing values in numeric columns:\n",
      "AF_RTU        0.359116\n",
      "AF_VAV_202    0.355983\n",
      "AF_VAV_106    0.355968\n",
      "AF_VAV_205    0.355952\n",
      "AF_VAV_203    0.355921\n",
      "AF_VAV_102    0.355906\n",
      "AF_VAV_206    0.355875\n",
      "AF_VAV_204    0.355875\n",
      "RH_VAV_205    0.355844\n",
      "RH_VAV_202    0.355844\n",
      "RH_VAV_203    0.355844\n",
      "RH_VAV_204    0.355844\n",
      "AF_VAV_103    0.355844\n",
      "RH_VAV_206    0.355844\n",
      "T_Sup_RTU     0.355844\n",
      "AF_VAV_104    0.355844\n",
      "AF_VAV_105    0.355844\n",
      "RH_VAV_106    0.355844\n",
      "RH_VAV_105    0.355844\n",
      "RH_VAV_104    0.355844\n",
      "T_VAV_105     0.355844\n",
      "RH_Sup_RTU    0.355844\n",
      "T_Ret_RTU     0.355844\n",
      "RH_Ret_RTU    0.355844\n",
      "T_VAV_102     0.355844\n",
      "T_VAV_103     0.355844\n",
      "T_VAV_104     0.355844\n",
      "T_VAV_106     0.355844\n",
      "RH_VAV_103    0.355844\n",
      "T_VAV_202     0.355844\n",
      "T_VAV_203     0.355844\n",
      "T_VAV_204     0.355844\n",
      "T_VAV_205     0.355844\n",
      "T_VAV_206     0.355844\n",
      "RH_VAV_102    0.355844\n",
      "dtype: float64\n",
      "Numeric columns T_Sup_RTU High percentage of missing values (35.58%)\n",
      "Numeric columns RH_Sup_RTU High percentage of missing values (35.58%)\n",
      "Numeric columns T_Ret_RTU High percentage of missing values (35.58%)\n",
      "Numeric columns RH_Ret_RTU High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_102 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_103 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_104 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_105 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_106 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_202 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_203 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_204 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_205 High percentage of missing values (35.58%)\n",
      "Numeric columns T_VAV_206 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_102 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_103 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_104 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_105 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_106 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_202 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_203 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_204 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_205 High percentage of missing values (35.58%)\n",
      "Numeric columns RH_VAV_206 High percentage of missing values (35.58%)\n",
      "Numeric columns AF_RTU High percentage of missing values (35.91%)\n",
      "Numeric columns AF_VAV_102 High percentage of missing values (35.59%)\n",
      "Numeric columns AF_VAV_103 High percentage of missing values (35.58%)\n",
      "Numeric columns AF_VAV_104 High percentage of missing values (35.58%)\n",
      "Numeric columns AF_VAV_105 High percentage of missing values (35.58%)\n",
      "Numeric columns AF_VAV_106 High percentage of missing values (35.60%)\n",
      "Numeric columns AF_VAV_202 High percentage of missing values (35.60%)\n",
      "Numeric columns AF_VAV_203 High percentage of missing values (35.59%)\n",
      "Numeric columns AF_VAV_204 High percentage of missing values (35.59%)\n",
      "Numeric columns AF_VAV_205 High percentage of missing values (35.60%)\n",
      "Numeric columns AF_VAV_206 High percentage of missing values (35.59%)\n",
      "\n",
      "=== outlier detection ===\n",
      "Column T_Sup_RTU found 643 outlier (Z-score > 3)\n",
      "Column T_Ret_RTU found 1788 outlier (Z-score > 3)\n",
      "Column T_VAV_103 found 1972 outlier (Z-score > 3)\n",
      "Column T_VAV_104 found 1170 outlier (Z-score > 3)\n",
      "Column T_VAV_105 found 1409 outlier (Z-score > 3)\n",
      "Column T_VAV_106 found 1555 outlier (Z-score > 3)\n",
      "Column T_VAV_202 found 1312 outlier (Z-score > 3)\n",
      "Column T_VAV_203 found 648 outlier (Z-score > 3)\n",
      "Column T_VAV_204 found 1155 outlier (Z-score > 3)\n",
      "Column T_VAV_205 found 1489 outlier (Z-score > 3)\n",
      "Column T_VAV_206 found 1480 outlier (Z-score > 3)\n",
      "Column AF_RTU found 2175 outlier (Z-score > 3)\n",
      "Column AF_VAV_102 found 2382 outlier (Z-score > 3)\n",
      "Column AF_VAV_103 found 2566 outlier (Z-score > 3)\n",
      "Column AF_VAV_104 found 2325 outlier (Z-score > 3)\n",
      "Column AF_VAV_105 found 2497 outlier (Z-score > 3)\n",
      "Column AF_VAV_106 found 2607 outlier (Z-score > 3)\n",
      "Column AF_VAV_202 found 2404 outlier (Z-score > 3)\n",
      "Column AF_VAV_203 found 2226 outlier (Z-score > 3)\n",
      "Column AF_VAV_204 found 2226 outlier (Z-score > 3)\n",
      "Column AF_VAV_205 found 2629 outlier (Z-score > 3)\n",
      "Column AF_VAV_206 found 2455 outlier (Z-score > 3)\n",
      "\n",
      "Data cleansing is complete and the results have been saved to ../../outputs/HVAC_cleaned_data.csv\n",
      "\n",
      "Post-cleaning data information.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64798 entries, 0 to 64797\n",
      "Data columns (total 86 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   TIMESTAMP       64798 non-null  datetime64[ns]\n",
      " 1   T_Stair_101     64798 non-null  object        \n",
      " 2   T_Room_102      64798 non-null  object        \n",
      " 3   T_Room_103      64798 non-null  object        \n",
      " 4   T_Room_104      64798 non-null  object        \n",
      " 5   T_Room_105      64798 non-null  object        \n",
      " 6   T_Room_106      64798 non-null  object        \n",
      " 7   T_Stair_201     64798 non-null  object        \n",
      " 8   T_Room_202      64798 non-null  object        \n",
      " 9   T_Room_203      64798 non-null  object        \n",
      " 10  T_Room_204      64798 non-null  object        \n",
      " 11  T_Room_205      64798 non-null  object        \n",
      " 12  T_Room_206      64798 non-null  object        \n",
      " 13  RH_Stair_101    64798 non-null  object        \n",
      " 14  RH_Room_102     64798 non-null  object        \n",
      " 15  RH_Room_103     64798 non-null  object        \n",
      " 16  RH_Room_104     64798 non-null  object        \n",
      " 17  RH_Room_105     64798 non-null  object        \n",
      " 18  RH_Room_106     64798 non-null  object        \n",
      " 19  RH_Stair_201    64798 non-null  object        \n",
      " 20  RH_Room_202     64798 non-null  object        \n",
      " 21  RH_Room_203     64798 non-null  object        \n",
      " 22  RH_Room_204     64798 non-null  object        \n",
      " 23  RH_Room_205     64798 non-null  object        \n",
      " 24  RH_Room_206     64798 non-null  object        \n",
      " 25  T_Sup_RTU       41740 non-null  float64       \n",
      " 26  RH_Sup_RTU      41740 non-null  float64       \n",
      " 27  T_Ret_RTU       41740 non-null  float64       \n",
      " 28  RH_Ret_RTU      41740 non-null  float64       \n",
      " 29  T_VAV_102       41740 non-null  float64       \n",
      " 30  T_VAV_103       41740 non-null  float64       \n",
      " 31  T_VAV_104       41740 non-null  float64       \n",
      " 32  T_VAV_105       41740 non-null  float64       \n",
      " 33  T_VAV_106       41740 non-null  float64       \n",
      " 34  T_VAV_202       41740 non-null  float64       \n",
      " 35  T_VAV_203       41740 non-null  float64       \n",
      " 36  T_VAV_204       41740 non-null  float64       \n",
      " 37  T_VAV_205       41740 non-null  float64       \n",
      " 38  T_VAV_206       41740 non-null  float64       \n",
      " 39  RH_VAV_102      41740 non-null  float64       \n",
      " 40  RH_VAV_103      41740 non-null  float64       \n",
      " 41  RH_VAV_104      41740 non-null  float64       \n",
      " 42  RH_VAV_105      41740 non-null  float64       \n",
      " 43  RH_VAV_106      41740 non-null  float64       \n",
      " 44  RH_VAV_202      41740 non-null  float64       \n",
      " 45  RH_VAV_203      41740 non-null  float64       \n",
      " 46  RH_VAV_204      41740 non-null  float64       \n",
      " 47  RH_VAV_205      41740 non-null  float64       \n",
      " 48  RH_VAV_206      41740 non-null  float64       \n",
      " 49  WH_RTU_Total    64798 non-null  object        \n",
      " 50  WH_RTU_Comp1    64798 non-null  object        \n",
      " 51  WH_RTU_Comp2    64798 non-null  object        \n",
      " 52  WH_RTU_Cond1    64798 non-null  object        \n",
      " 53  WH_RTU_Cond2    64798 non-null  object        \n",
      " 54  WH_RTU_Sup_Fan  64798 non-null  object        \n",
      " 55  WH_RTU_VAV102   64798 non-null  object        \n",
      " 56  WH_RTU_VAV103   64798 non-null  object        \n",
      " 57  WH_RTU_VAV104   64798 non-null  object        \n",
      " 58  WH_RTU_VAV105   64798 non-null  object        \n",
      " 59  WH_RTU_VAV106   64798 non-null  object        \n",
      " 60  WH_RTU_VAV202   64798 non-null  object        \n",
      " 61  WH_RTU_VAV203   64798 non-null  object        \n",
      " 62  WH_RTU_VAV204   64798 non-null  object        \n",
      " 63  WH_RTU_VAV205   64798 non-null  object        \n",
      " 64  WH_RTU_VAV206   64798 non-null  object        \n",
      " 65  AF_RTU          41528 non-null  float64       \n",
      " 66  AF_VAV_102      41736 non-null  float64       \n",
      " 67  AF_VAV_103      41740 non-null  float64       \n",
      " 68  AF_VAV_104      41740 non-null  float64       \n",
      " 69  AF_VAV_105      41740 non-null  float64       \n",
      " 70  AF_VAV_106      41732 non-null  float64       \n",
      " 71  AF_VAV_202      41731 non-null  float64       \n",
      " 72  AF_VAV_203      41735 non-null  float64       \n",
      " 73  AF_VAV_204      41738 non-null  float64       \n",
      " 74  AF_VAV_205      41733 non-null  float64       \n",
      " 75  AF_VAV_206      41738 non-null  float64       \n",
      " 76  source_file_x   64798 non-null  object        \n",
      " 77  T_out           64798 non-null  object        \n",
      " 78  RH_out          64798 non-null  object        \n",
      " 79  BP              64798 non-null  object        \n",
      " 80  Dir_Solar       64798 non-null  object        \n",
      " 81  Dif_Solar       64798 non-null  object        \n",
      " 82  Glo_Solar       64798 non-null  object        \n",
      " 83  WS              64798 non-null  object        \n",
      " 84  WD              64798 non-null  object        \n",
      " 85  source_file_y   64798 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(35), object(50)\n",
      "memory usage: 42.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            TIMESTAMP  T_Stair_101   T_Room_102   T_Room_103   T_Room_104  \\\n0 2021-02-23 00:00:00  10.78888889  15.58333333  20.42222222  16.40555556   \n1 2021-02-23 00:01:00  10.78333333  15.58333333  20.38888889  16.40555556   \n2 2021-02-23 00:02:00  10.78333333  15.56111111  20.42222222  16.38888889   \n3 2021-02-23 00:03:00  10.78333333  15.57777778  20.38333333  16.39444444   \n4 2021-02-23 00:04:00  10.78333333  15.54444444  20.41111111  16.38888889   \n\n    T_Room_105   T_Room_106  T_Stair_201   T_Room_202   T_Room_203  ...  \\\n0        19.25  17.84444444  12.98888889  18.90555556  16.38888889  ...   \n1  19.23333333  17.81666667  12.98333333  18.93333333  16.38888889  ...   \n2  19.24444444  17.83333333  12.97222222  18.91111111  16.41111111  ...   \n3  19.24444444  17.80555556  12.97222222  18.93333333  16.36111111  ...   \n4  19.23333333  17.82777778  12.96111111  18.93333333  16.39444444  ...   \n\n             source_file_x        T_out RH_out          BP Dir_Solar  \\\n0  Building_FF_Heating.csv         1.25   89.8  98377.8156     0.106   \n1  Building_FF_Heating.csv  1.266666667   89.5  98377.8156     0.053   \n2  Building_FF_Heating.csv          1.3   89.1  98377.8156     0.106   \n3  Building_FF_Heating.csv  1.361111111   88.5  98377.8156     0.106   \n4  Building_FF_Heating.csv         1.35   88.3  98377.8156     0.053   \n\n  Dif_Solar Glo_Solar   WS   WD           source_file_y  \n0     0.092    -1.358  0.0  0.0  Weather_FF_Heating.csv  \n1     0.092    -1.409  0.0  0.0  Weather_FF_Heating.csv  \n2     0.092    -1.358  0.0  0.0  Weather_FF_Heating.csv  \n3     0.138    -1.409  0.0  0.0  Weather_FF_Heating.csv  \n4     0.092    -1.409  0.0  0.0  Weather_FF_Heating.csv  \n\n[5 rows x 86 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TIMESTAMP</th>\n      <th>T_Stair_101</th>\n      <th>T_Room_102</th>\n      <th>T_Room_103</th>\n      <th>T_Room_104</th>\n      <th>T_Room_105</th>\n      <th>T_Room_106</th>\n      <th>T_Stair_201</th>\n      <th>T_Room_202</th>\n      <th>T_Room_203</th>\n      <th>...</th>\n      <th>source_file_x</th>\n      <th>T_out</th>\n      <th>RH_out</th>\n      <th>BP</th>\n      <th>Dir_Solar</th>\n      <th>Dif_Solar</th>\n      <th>Glo_Solar</th>\n      <th>WS</th>\n      <th>WD</th>\n      <th>source_file_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-02-23 00:00:00</td>\n      <td>10.78888889</td>\n      <td>15.58333333</td>\n      <td>20.42222222</td>\n      <td>16.40555556</td>\n      <td>19.25</td>\n      <td>17.84444444</td>\n      <td>12.98888889</td>\n      <td>18.90555556</td>\n      <td>16.38888889</td>\n      <td>...</td>\n      <td>Building_FF_Heating.csv</td>\n      <td>1.25</td>\n      <td>89.8</td>\n      <td>98377.8156</td>\n      <td>0.106</td>\n      <td>0.092</td>\n      <td>-1.358</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Weather_FF_Heating.csv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-02-23 00:01:00</td>\n      <td>10.78333333</td>\n      <td>15.58333333</td>\n      <td>20.38888889</td>\n      <td>16.40555556</td>\n      <td>19.23333333</td>\n      <td>17.81666667</td>\n      <td>12.98333333</td>\n      <td>18.93333333</td>\n      <td>16.38888889</td>\n      <td>...</td>\n      <td>Building_FF_Heating.csv</td>\n      <td>1.266666667</td>\n      <td>89.5</td>\n      <td>98377.8156</td>\n      <td>0.053</td>\n      <td>0.092</td>\n      <td>-1.409</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Weather_FF_Heating.csv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-02-23 00:02:00</td>\n      <td>10.78333333</td>\n      <td>15.56111111</td>\n      <td>20.42222222</td>\n      <td>16.38888889</td>\n      <td>19.24444444</td>\n      <td>17.83333333</td>\n      <td>12.97222222</td>\n      <td>18.91111111</td>\n      <td>16.41111111</td>\n      <td>...</td>\n      <td>Building_FF_Heating.csv</td>\n      <td>1.3</td>\n      <td>89.1</td>\n      <td>98377.8156</td>\n      <td>0.106</td>\n      <td>0.092</td>\n      <td>-1.358</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Weather_FF_Heating.csv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-02-23 00:03:00</td>\n      <td>10.78333333</td>\n      <td>15.57777778</td>\n      <td>20.38333333</td>\n      <td>16.39444444</td>\n      <td>19.24444444</td>\n      <td>17.80555556</td>\n      <td>12.97222222</td>\n      <td>18.93333333</td>\n      <td>16.36111111</td>\n      <td>...</td>\n      <td>Building_FF_Heating.csv</td>\n      <td>1.361111111</td>\n      <td>88.5</td>\n      <td>98377.8156</td>\n      <td>0.106</td>\n      <td>0.138</td>\n      <td>-1.409</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Weather_FF_Heating.csv</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-02-23 00:04:00</td>\n      <td>10.78333333</td>\n      <td>15.54444444</td>\n      <td>20.41111111</td>\n      <td>16.38888889</td>\n      <td>19.23333333</td>\n      <td>17.82777778</td>\n      <td>12.96111111</td>\n      <td>18.93333333</td>\n      <td>16.39444444</td>\n      <td>...</td>\n      <td>Building_FF_Heating.csv</td>\n      <td>1.35</td>\n      <td>88.3</td>\n      <td>98377.8156</td>\n      <td>0.053</td>\n      <td>0.092</td>\n      <td>-1.409</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Weather_FF_Heating.csv</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 86 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execution of the cleaning process\n",
    "print(\"Begin the data cleansing process...\")\n",
    "cleaned_data = general_data_cleaning(final_data)\n",
    "# cleaned_data = hvac_specific_cleaning(cleaned_data)\n",
    "\n",
    "\n",
    "# Save cleaned data\n",
    "cleaned_data.to_csv('../../outputs/HVAC_cleaned_data.csv', index=False)\n",
    "print(\"\\nData cleansing is complete and the results have been saved to ../../outputs/HVAC_cleaned_data.csv\")\n",
    "\n",
    "# Display of information on cleaned data\n",
    "print(\"\\nPost-cleaning data information.\")\n",
    "display(cleaned_data.info())\n",
    "display(cleaned_data.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-03T01:02:19.563258400Z",
     "start_time": "2025-04-03T01:02:14.126074800Z"
    }
   },
   "id": "5c75664906c6feff",
   "execution_count": 141
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
